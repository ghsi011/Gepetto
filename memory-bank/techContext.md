# Technical Context

## Primary Technologies
• **Python 3.9+** – Language used for the entire plugin; must match IDA's embedded interpreter.
• **Hex-Rays IDA Pro SDK** – Provides `idaapi`, `ida_hexrays`, `ida_kernwin` modules used for UI integration and decompiler interaction.
• **gettext** – Internationalisation of UI strings via `.po/.mo` files located in `gepetto/locales`.
• **Large-Language-Model SDKs** – Installed via `requirements.txt`:
  * `openai` for OpenAI & OpenAI-compatible APIs
  * `groq`, `together`, `ollama` client libraries
  * `azure-identity` for Azure OpenAI authentication

## Project Layout
```
Gepetto/
├─ gepetto.py              # IDA entry-point script (loader)
├─ gepetto/                # Core plugin package
│  ├─ ida/                 # IDA-specific UI & handlers
│  ├─ models/              # LLM provider adapters & manager
│  ├─ config.py / config.ini
│  └─ locales/             # i18n resources
└─ memory-bank/            # Persistent design documentation (generated by Cursor)
```

## Development Setup
1. Clone repo into a normal Python environment for testing (outside IDA).
2. Create a virtual environment and `pip install -r requirements.txt`.
3. For in-IDA testing, copy `gepetto.py` + `gepetto/` to `%IDAUSR%/plugins` and ensure the same packages are installed in IDA's Python dir.
4. Provide API keys in `gepetto/config.ini` or environment variables.

## Technical Constraints
• Must run under IDA's embedded Python which is often slightly behind mainstream releases.
• Network latency to LLM providers can be significant; async design mitigates UI blocking.
• Hex-Rays license required for decompiler API access.
• Many providers impose rate limits & cost considerations.

## Dependencies & External Services
| Purpose | Library | Notes |
|---------|---------|-------|
| OpenAI models | openai | GPT-3.5, GPT-4, GPT-4o, **o4-mini, o3** |
| Azure OpenAI | azure-identity | Provides AD token auth |
| Groq Cloud | groq | Llama-3 series, Mixtral |
| Together AI | together | Large mixture models |
| Local Ollama | ollama | Any local model with REST server |

## Build/Run Commands
```sh
# Install deps
pip install -r requirements.txt

# Run unit tests (future)
pytest

# Package localization changes
sh gepetto/locales/generate_mo_files.sh
``` 